{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e149c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c337e9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 10 variables whereas the saved optimizer has 18 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "doctor_cnn = load_model(\"doctor_cnn_model.keras\")\n",
    "nurse_cnn = load_model(\"nurse_cnn_model.keras\")\n",
    "staff_cnn = load_model(\"staff_cnn_model.keras\")\n",
    "patient_cnn = load_model(\"patient_cnn_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f4e8141",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"preprocessed_data_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ded982d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and fit scalers\n",
    "doctor_scaler = StandardScaler()\n",
    "nurse_scaler = StandardScaler()\n",
    "staff_scaler = StandardScaler()\n",
    "patient_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dff4d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "doctor_features = df[[col for col in df.columns if \"Doctors\" in col]]\n",
    "nurse_features = df[[col for col in df.columns if \"Nurses\" in col]]\n",
    "staff_features = df[['Patients who \"Agree\" that staff took their preferences into account',\n",
    "       'Patients who \"Disagree\" or \"Strongly Disagree\" that staff took their preferences into account',\n",
    "       'Patients who \"Strongly Agree\" that staff took their preferences into account',\n",
    "       'Staff \"always\" explained', 'Staff \"always\" explained new medications',\n",
    "       'Staff \"always\" explained possible side effects',\n",
    "       'Staff \"sometimes\" or \"never\" explained',\n",
    "       'Staff \"sometimes\" or \"never\" explained new medications',\n",
    "       'Staff \"sometimes\" or \"never\" explained possible side effects',\n",
    "       'Staff \"usually\" explained',\n",
    "       'Staff \"usually\" explained new medications',\n",
    "       'Staff \"usually\" explained possible side effects']]\n",
    "patient_features = df[['\"Always\" quiet at night',\n",
    "       '\"NO\", patients would not recommend the hospital (they probably would not or definitely would not recommend it)',\n",
    "       '\"Sometimes\" or \"never\" quiet at night', '\"Usually\" quiet at night',\n",
    "       '\"YES\", patients would definitely recommend the hospital',\n",
    "       '\"YES\", patients would probably recommend the hospital']]\n",
    "\n",
    "# Assume scaler was used and saved separately for each feature group\n",
    "doctor_scaled = doctor_scaler.fit_transform(doctor_features)\n",
    "nurse_scaled = nurse_scaler.fit_transform(nurse_features)\n",
    "staff_scaled = staff_scaler.fit_transform(staff_features)\n",
    "patient_scaled = patient_scaler.fit_transform(patient_features)\n",
    "\n",
    "# Reshape for CNN input (samples, timesteps, 1)\n",
    "doctor_input = doctor_scaled.reshape((doctor_scaled.shape[0], doctor_scaled.shape[1], 1))\n",
    "nurse_input = nurse_scaled.reshape((nurse_scaled.shape[0], nurse_scaled.shape[1], 1))\n",
    "staff_input = staff_scaled.reshape((staff_scaled.shape[0], staff_scaled.shape[1], 1))\n",
    "patient_input = patient_scaled.reshape((patient_scaled.shape[0], patient_scaled.shape[1], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb11852b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "doctor_output = doctor_cnn.predict(doctor_input)\n",
    "nurse_output = nurse_cnn.predict(nurse_input)\n",
    "staff_output = staff_cnn.predict(staff_input)\n",
    "patient_output = patient_cnn.predict(patient_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4049d7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Input shape matches the number of features in your tabular data\n",
    "input_tensor = Input(shape=(12,))\n",
    "x = Dense(64, activation='relu')(input_tensor)\n",
    "x = Dense(32, activation='relu')(x)  # This could be your embedding layer\n",
    "output_tensor = Dense(1, activation='sigmoid')(x)  # Or softmax for classification\n",
    "\n",
    "input_layer = Input(shape=(6,))\n",
    "x = Dense(64, activation='relu')(input_layer)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "output_layer = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "doctor_cnn = Model(inputs=input_tensor, outputs=output_tensor)\n",
    "nurse_cnn = Model(inputs=input_tensor, outputs=output_tensor)\n",
    "patient_cnn = Model(inputs=input_layer, outputs=output_layer)\n",
    "staff_cnn = Model(inputs=input_tensor, outputs=output_tensor)\n",
    "##Use feature vectors from intermediate layers (better if you want richer features)\n",
    "\n",
    "doctor_embedding_model = Model(inputs=doctor_cnn.input, outputs=doctor_cnn.layers[-2].output)\n",
    "nurse_embedding_model = Model(inputs = nurse_cnn.input, outputs = nurse_cnn.layers[-2].output)\n",
    "staff_embedding_model = Model(inputs= staff_cnn.input, outputs= staff_cnn.layers[-2].output)\n",
    "patient_embedding_model = Model(inputs = patient_cnn.input, outputs = patient_cnn.layers[-2].output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f89260f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "doctor_output = doctor_embedding_model.predict(doctor_input)\n",
    "nurse_output = nurse_embedding_model.predict(nurse_input)\n",
    "staff_output = staff_embedding_model.predict(staff_input)\n",
    "patient_output = patient_embedding_model.predict(patient_input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e920d385",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "combined_features = np.concatenate([doctor_output, nurse_output, staff_output, patient_output], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28490249",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Total Ratings\"] = (\n",
    "    df['Patients who gave a rating of \"6\" or lower (low)'] +\n",
    "    df['Patients who gave a rating of \"7\" or \"8\" (medium)'] +\n",
    "    df['Patients who gave a rating of \"9\" or \"10\" (high)']\n",
    ")\n",
    "\n",
    "# Weighted average: 1 for low, 2 for medium, 3 for high\n",
    "df[\"Rating\"] = (\n",
    "    1*df['Patients who gave a rating of \"6\" or lower (low)'] +\n",
    "    2*df['Patients who gave a rating of \"7\" or \"8\" (medium)'] +\n",
    "    3*df['Patients who gave a rating of \"9\" or \"10\" (high)']\n",
    ") / df[\"Total Ratings\"]\n",
    "\n",
    "\n",
    "df[\"Rating\"] = df[\"Rating\"] * (5 / 3)\n",
    "df['Rating'] = df['Rating'].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00230dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.005440349716859724\n",
      "R²: 0.9143850771437451\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "y = df[\"Rating\"]  # Target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_features, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = rf_model.predict(X_test)\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"R²:\", r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55dbb68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "#joblib.dump(rf_model, \"combined_rf_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43de97c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "rf_model = joblib.load(\"combined_rf_model.pkl\")\n",
    "\n",
    "def predict_rating(hcahps_input_df):\n",
    "    # Step 1: Load scalers and CNN models\n",
    "    doctor_scaler = joblib.load(\"doctor_scaler.pkl\")\n",
    "    nurse_scaler = joblib.load(\"nurse_scaler.pkl\")\n",
    "    staff_scaler = joblib.load(\"staff_scaler.pkl\")\n",
    "    patient_scaler = joblib.load(\"patient_scaler.pkl\")\n",
    "\n",
    "    doctor_cnn = tf.keras.models.load_model(\"doctor_cnn_model.h5\")\n",
    "    nurse_cnn = tf.keras.models.load_model(\"nurse_cnn_model.h5\")\n",
    "    staff_cnn = tf.keras.models.load_model(\"staff_cnn_model.h5\")\n",
    "    patient_cnn = tf.keras.models.load_model(\"patient_cnn_model.h5\")\n",
    "\n",
    "    rf_model = joblib.load(\"combined_rf_model.pkl\")\n",
    "\n",
    "    # Step 2: Extract and scale features\n",
    "    doctor_features = doctor_scaler.transform(hcahps_input_df[[col for col in hcahps_input_df.columns if \"Doctor\" in col]])\n",
    "    nurse_features = nurse_scaler.transform(hcahps_input_df[[col for col in hcahps_input_df.columns if \"Nurse\" in col]])\n",
    "    staff_features = staff_scaler.transform(hcahps_input_df[[col for col in hcahps_input_df.columns if \"Staff\" in col]])\n",
    "    patient_features = patient_scaler.transform(hcahps_input_df[[col for col in hcahps_input_df.columns if \"Patient\" in col and \"rating\" not in col.lower()]])\n",
    "\n",
    "    # Step 3: Reshape for CNNs\n",
    "    doctor_input = doctor_features.reshape((doctor_features.shape[0], doctor_features.shape[1], 1))\n",
    "    nurse_input = nurse_features.reshape((nurse_features.shape[0], nurse_features.shape[1], 1))\n",
    "    staff_input = staff_features.reshape((staff_features.shape[0], staff_features.shape[1], 1))\n",
    "    patient_input = patient_features.reshape((patient_features.shape[0], patient_features.shape[1], 1))\n",
    "\n",
    "    # Step 4: CNN outputs\n",
    "    doctor_output = doctor_cnn.predict(doctor_input)\n",
    "    nurse_output = nurse_cnn.predict(nurse_input)\n",
    "    staff_output = staff_cnn.predict(staff_input)\n",
    "    patient_output = patient_cnn.predict(patient_input)\n",
    "\n",
    "    # Step 5: Combine CNN outputs as features\n",
    "    combined_features = np.concatenate([doctor_output, nurse_output, staff_output, patient_output], axis=1)\n",
    "\n",
    "    # Step 6: Final prediction using Random Forest\n",
    "    final_prediction = rf_model.predict(combined_features)\n",
    "    return final_prediction\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdd4c47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef41588b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
